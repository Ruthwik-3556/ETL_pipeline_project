# ETL_pipeline_project
implemented a modular ETL pipeline where data is extracted from a CSV file, transformed to handle missing values and enforce data integrity using Pandas, and loaded into a SQLite database. The processed data was validated using SQL queries and visualized using Matplotlib

# ğŸ“Š ETL Pipeline Project (CSV â†’ SQLite Database)

## ğŸ“Œ Project Overview
This project demonstrates a complete **ETL (Extract, Transform, Load) pipeline** using Python.  
Employee data is extracted from a CSV file, cleaned and transformed using Pandas, and loaded into a SQLite database.  
The project is implemented in a **modular and scalable structure**, following real-world data engineering practices.

---

## ğŸ› ï¸ Tools & Technologies
- **Python 3**
- **Pandas** â€“ Data extraction & transformation
- **SQLite** â€“ Lightweight relational database
- **Jupyter Notebook** â€“ Development environment
- **Matplotlib** â€“ Data visualization

---

## ğŸ“‚ Project Structure
ETL_Pipeline_Project/
â”‚
â”œâ”€â”€ data.csv # Source CSV file
â”œâ”€â”€ extract.ipynb # Extract module
â”œâ”€â”€ transform.ipynb # Transform module
â”œâ”€â”€ load.ipynb # Load module
â”œâ”€â”€ database.ipynb # Database connection & table creation
â”œâ”€â”€ main.ipynb # Main ETL pipeline controller
â”œâ”€â”€ company.db # SQLite database
â”œâ”€â”€ ETL_Project_Report.pdf# Project report with visualizations
â””â”€â”€ README.md # Project documentation

yaml
Copy code

---

## ğŸ” ETL Pipeline Workflow

CSV File
â†“
Extract (read CSV using Pandas)
â†“
Transform (handle missing values, clean data)
â†“
Load (store into SQLite database)
â†“
Database Table

yaml
Copy code

---

## ğŸ” ETL Stages Explained

### 1ï¸âƒ£ Extract
- Reads employee data from `data.csv`
- Loads data into a Pandas DataFrame

### 2ï¸âƒ£ Transform
- Handles missing values in `age` and `salary`
- Converts `joining_date` to datetime format
- Enforces correct data types
- Applies basic data validation

### 3ï¸âƒ£ Load
- Creates a SQLite database (`company.db`)
- Inserts cleaned data into the `employees` table

---

## ğŸ“Š Data Visualizations
The following visualizations are included in the project report:
- **Average Salary by Department** (Bar Chart)
- **Age Distribution of Employees** (Histogram)

---

## â–¶ï¸ How to Run the Project

1. Ensure all `.ipynb` files are in the same directory
2. Open **Jupyter Notebook**
3. Open and run `main.ipynb`
4. The ETL pipeline will execute automatically
5. Final data will be stored in `company.db`

---

## âœ… Output
- Cleaned employee data stored in SQLite database
- Verified using SQL queries
- Visual insights generated using Matplotlib
- Complete documentation in PDF format

---

## ğŸ§  Viva / Evaluation Summary
> â€œThis project implements a modular ETL pipeline that extracts data from a CSV file, transforms it using Pandas for data quality and consistency, and loads it into a SQLite database. The processed data is validated and visualized for analysis.â€

---

## ğŸ“Œ Conclusion
This project successfully demonstrates core data engineering concepts including:
- Data extraction
- Data cleaning & transformation
- Database loading
- Data visualization
- Modular project design

---

## ğŸ‘¤ Author
**Ruthwik Chetan Naik**

---

## ğŸ“„ License
This project is created for academic and educational purposes.
